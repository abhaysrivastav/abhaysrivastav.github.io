---
layout: default
title: Database Indexing - Interview Notes
---

# Database Indexing - Interview Notes ğŸ“š

## Table of Contents
1. [Core Concepts](#core-concepts)
2. [Index Types](#index-types)
3. [Optimization Patterns](#optimization-patterns)
4. [Interview Templates](#interview-templates)
5. [Quick Reference](#quick-reference)s

---

## Core Concepts

### What is an Index?

```markdown
Problem:
â””â”€> Finding data without index = Full table scan
    "Search through every book in library one by one"

Solution:
â””â”€> Index = Separate data structure optimized for searching
    "Like index at back of textbook - jump directly to page"

Key Insight:
â”œâ”€> Indexes minimize disk reads
â”œâ”€> Transform random access to structured path
â””â”€> Trade storage space for query speed
```

### How Databases Store Data

```markdown
Without Index (Heap File):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rows stored in no particular order     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚ â”‚ id â”‚ username â”‚     email      â”‚     â”‚
â”‚ â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚ â”‚ 5  â”‚ raj      â”‚ raj@mail.com   â”‚     â”‚
â”‚ â”‚ 1  â”‚ abhay    â”‚ abhay@mail.com â”‚     â”‚
â”‚ â”‚ 3  â”‚ priya    â”‚ priya@mail.com â”‚     â”‚
â”‚ â”‚ 2  â”‚ amit     â”‚ amit@mail.com  â”‚     â”‚
â”‚ â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                        â”‚
â”‚ Query: SELECT * WHERE id = 3           â”‚
â”‚ â””â”€> Must scan ALL rows! ğŸ˜±             â”‚
â”‚     Time: O(n) - Very slow!            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

With Index (B-tree):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Index maintains sorted structure       â”‚
â”‚        Root: [5]                       â”‚
â”‚       /         \                      â”‚
â”‚    [1, 3]      [10, 15]                â”‚
â”‚                                        â”‚
â”‚ Query: SELECT * WHERE id = 3           â”‚
â”‚ â””â”€> Traverse tree: Rootâ†’Leftâ†’Found âœ…  â”‚
â”‚     Time: O(log n) - Fast!             â”‚
â”‚     Disk reads: 2-3 pages only         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Index Trade-offs

```markdown
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Benefits vs Costs                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  âœ… Benefits:                                      â”‚
â”‚  â”œâ”€ Fast reads (100-1000x improvement)             â”‚
â”‚  â”œâ”€ Efficient range queries                        â”‚
â”‚  â”œâ”€ Support for sorting (ORDER BY)                 â”‚
â”‚  â””â”€ Enable unique constraints                      â”‚
â”‚                                                    â”‚
â”‚  âŒ Costs:                                         â”‚
â”‚  â”œâ”€ Extra disk space (sometimes = table size)      â”‚
â”‚  â”œâ”€ Slower writes (update index + table)           â”‚
â”‚  â”œâ”€ Memory overhead (buffer pool pressure)         â”‚
â”‚  â””â”€ Maintenance complexity                         â”‚
â”‚                                                    â”‚
â”‚  When Indexes Hurt:                                â”‚
â”‚  â”œâ”€ Small tables (< 1000 rows)                     â”‚
â”‚  â”œâ”€ Write-heavy workloads (logging, metrics)       â”‚
â”‚  â”œâ”€ Low cardinality columns (gender, status)       â”‚
â”‚  â””â”€ Too many indexes (every write updates all)     â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Index Types

### 1. B-Tree Indexes (Default Choice)

**Structure:**
```markdown
B-tree Node Structure:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [key1 | ptr1 | key2 | ptr2 | key3] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚              â”‚
        â–¼              â–¼              â–¼
   Child nodes or leaf data

Properties:
â”œâ”€ Self-balancing (all leaves same depth)
â”œâ”€ Sorted keys within each node
â”œâ”€ Node size = Disk page size (8KB typical)
â””â”€ M-way tree (hundreds of children per node)

Example: Finding id=350
     [100, 500]           â—„â”€â”€ Root (1 disk read)
      /        \
  [50,150]   [300,400]    â—„â”€â”€ Internal (1 disk read)
              /      \
        [350,375] [425,450] â—„â”€â”€ Leaf (1 disk read)
                 â–²
            Found it! (3 total disk reads)
```

**When to Use:**
```sql
-- Perfect for B-tree:
SELECT * FROM users WHERE id = 123;           -- Equality
SELECT * FROM posts WHERE created_at > '2024-01-01'; -- Range
SELECT * FROM users ORDER BY username;        -- Sorting
SELECT * FROM tweets WHERE user_id IN (1,2,3); -- Multiple values

-- Create B-tree index (default):
CREATE INDEX idx_users_email ON users(email);
```

**Real-World Examples:**
```markdown
PostgreSQL:
â”œâ”€ Primary keys â†’ B-tree (automatic)
â”œâ”€ Unique constraints â†’ B-tree (automatic)
â””â”€ Default index type for CREATE INDEX

MongoDB:
â”œâ”€ _id field â†’ B-tree (automatic)
â””â”€> db.users.createIndex({ email: 1 })

MySQL (InnoDB):
â””â”€> Uses B+tree variant (all data in leaves)
```

**Strengths:**
```markdown
âœ… Balanced workloads (reads + writes)
âœ… Range queries (age > 25, date BETWEEN)
âœ… Sorting (ORDER BY efficient)
âœ… Prefix matching (email LIKE 'abc%')
âœ… Predictable O(log n) performance
```

---

### 2. LSM Trees (Write-Heavy Workloads)

**Problem B-trees Solve Poorly:**
```markdown
Write-Heavy Scenario:
â””â”€> DataDog ingesting 100,000 metrics/second

B-tree Bottleneck:
â”œâ”€> Each write = Find leaf + Read page + Update + Write back
â”œâ”€> Random disk seeks kill performance
â””â”€> Time: 10ms per write â†’ Can't keep up! ğŸ˜±

LSM Solution:
â”œâ”€> Batch writes in memory
â”œâ”€> Flush sequentially to disk
â””â”€> Time: 0.1ms per write â†’ 100x faster! âœ…
```

**How LSM Trees Work:**
```markdown
Write Path:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Memtable (In-Memory)                â”‚
â”‚    â””â”€> Red-black tree or skip list     â”‚
â”‚        Insert: O(log n) in RAM         â”‚
â”‚                                        â”‚
â”‚ 2. Write-Ahead Log (WAL)               â”‚
â”‚    â””â”€> Sequential append to disk       â”‚
â”‚        Ensures durability              â”‚
â”‚                                        â”‚
â”‚ 3. Flush to SSTable (Immutable)        â”‚
â”‚    â””â”€> When memtable full (~4MB)       â”‚
â”‚        Sequential write (very fast!)   â”‚
â”‚                                        â”‚
â”‚ 4. Compaction (Background)             â”‚
â”‚    â””â”€> Merge SSTables periodically     â”‚
â”‚        Remove duplicates/deletes       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Storage on Disk:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memtable (current, in RAM)            â”‚
â”‚  â”œâ”€ key1: value1                       â”‚
â”‚  â”œâ”€ key2: value2                       â”‚
â”‚  â””â”€ key3: value3                       â”‚
â”‚                                        â”‚
â”‚  SSTable-4 (newest, on disk)           â”‚
â”‚  SSTable-3                             â”‚
â”‚  SSTable-2                             â”‚
â”‚  SSTable-1 (oldest)                    â”‚
â”‚                                        â”‚
â”‚  Write = Append to memtable âœ…         â”‚
â”‚  Read = Check all layers ğŸ˜±            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Read Optimization:**
```markdown
Problem: Multiple SSTables to check

Solutions:
â”œâ”€ Bloom Filters
â”‚  â””â”€> "Is key definitely NOT in this file?"
â”‚      95% of SSTables skipped!
â”‚
â”œâ”€ Sparse Index
â”‚  â””â”€> Range check: Does SSTable contain key range?
â”‚      Skip entire files
â”‚
â””â”€ Compaction Strategy
   â”œâ”€ Size-tiered: Few files, more overlap
   â””â”€ Leveled: More files, less overlap
```

**Performance Comparison:**
```markdown
Operation          | B-tree  | LSM-tree
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Write (single)     | 10ms    | 0.1ms âœ…
Read (point query) | 5ms     | 20ms âš ï¸
Range scan         | 10ms    | 30ms âš ï¸
Bulk write         | Slow    | Fast âœ…

Conclusion:
â”œâ”€ LSM = Write-optimized (10-100x faster writes)
â””â”€ B-tree = Read-optimized (2-5x faster reads)
```

**Real-World Examples:**
```markdown
Cassandra:
â””â”€> Netflix viewing events (billions/day)

RocksDB:
â””â”€> Facebook social interactions (millions/sec)

DynamoDB:
â””â”€> LSM-style architecture for high write throughput

Use Cases:
â”œâ”€ Time-series data (metrics, logs)
â”œâ”€ Event streaming (Kafka, analytics)
â”œâ”€ IoT data ingestion
â””â”€ Write-heavy applications (90:10 write:read)
```

---

### 3. Hash Indexes (Exact Match Only)

**Structure:**
```markdown
Hash Index = Persistent HashMap

Example:
buckets[hash("alice@example.com")] â†’ ptr to page 1
buckets[hash("bob@example.com")]   â†’ ptr to page 2
buckets[hash("charlie@example.com")] â†’ ptr to page 1 (collision!)

Collision Handling:
â””â”€> Chaining (linked list in bucket)
    Or overflow pages

Performance:
â”œâ”€ Exact match: O(1) âœ…
â”œâ”€ Range query: Impossible âŒ
â””â”€> Sorting: Impossible âŒ
```

**When to Use:**
```sql
-- Good for hash index:
SELECT * FROM users WHERE email = 'exact@match.com';

-- Bad for hash index:
SELECT * FROM users WHERE email LIKE 'abc%';  -- âŒ
SELECT * FROM users WHERE age > 25;           -- âŒ
SELECT * FROM users ORDER BY email;           -- âŒ

-- Create hash index (PostgreSQL):
CREATE INDEX idx_email_hash ON users USING HASH(email);
```

**Reality Check:**
```markdown
Why Hash Indexes are Rare:

B-tree vs Hash for exact match:
â”œâ”€ Hash: O(1) â†’ 1-2 disk reads
â”œâ”€ B-tree: O(log n) â†’ 2-3 disk reads
â””â”€> Difference: Negligible in practice!

B-tree advantages:
â”œâ”€ Also supports range queries âœ…
â”œâ”€ Also supports sorting âœ…
â”œâ”€ Smaller size (better compression)
â””â”€> More versatile!

When Hash Wins:
â”œâ”€ In-memory databases (Redis)
â”œâ”€ MySQL MEMORY engine (deprecated)
â””â”€> When range queries NEVER needed
```

**Interview Tip:**
```markdown
âŒ Don't overemphasize hash indexes

Better answer:
"For exact matches, B-trees perform nearly as well as hash indexes
 while also supporting range queries and sorting. I'd default to
 B-trees unless I have a specific reason to use hash indexes,
 like an in-memory cache where exact-match performance is critical."

Focusing too much on hash indexes might seem out of touch! ğŸ˜…
```

---

### 4. Geospatial Indexes

**The Problem:**
```markdown
Scenario: Find restaurants within 5 miles

Naive Approach:
CREATE INDEX idx_lat ON restaurants(latitude);
CREATE INDEX idx_lng ON restaurants(longitude);

Query:
SELECT * FROM restaurants
WHERE latitude BETWEEN 37.7 AND 37.8
  AND longitude BETWEEN -122.5 AND -122.4;

Problem:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Search Rectangle               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Too many false positives!        â”‚  â”‚
â”‚  â”‚                                  â”‚  â”‚
â”‚  â”‚         â— Actual circle          â”‚  â”‚
â”‚  â”‚        â— â— search area           â”‚  â”‚
â”‚  â”‚       â—   â—                      â”‚  â”‚
â”‚  â”‚        â— â—                       â”‚  â”‚
â”‚  â”‚         â—                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                        â”‚
â”‚ Rectangle includes distant corners!    â”‚
â”‚ Need to filter out ~40% of results ğŸ˜±  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Need: Index that understands 2D proximity!
```

#### Approach 1: Geohash

**How it Works:**
```markdown
Concept: Convert 2D â†’ 1D string preserving proximity

Process:
1. Divide world into 4 quadrants (00, 01, 10, 11)
2. Subdivide each quadrant into 4 more
3. Continue until desired precision
4. Encode as base32 string

Example:
"dr" â†’ San Francisco (city)
"dr5" â†’ Mission District (neighborhood)
"dr5ru" â†’ Specific block (100m precision)
"dr5ru7" â†’ Building (25m precision)

Key Property:
â”œâ”€> Nearby locations share prefix
â”œâ”€> "dr5ru123" and "dr5ru456" are close!
â””â”€> Can use B-tree on geohash strings!
```

**Implementation:**
```sql
-- PostgreSQL/PostGIS
CREATE TABLE restaurants (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255),
    latitude DECIMAL(10, 8),
    longitude DECIMAL(11, 8),
    geohash VARCHAR(12)  -- Generated column
);

CREATE INDEX idx_geohash ON restaurants(geohash);

-- Query nearby (B-tree range scan!)
SELECT * FROM restaurants
WHERE geohash BETWEEN 'dr5ru' AND 'dr5ru~'
  AND ST_Distance(point, target) < 5000;  -- Final filter
```

**Redis Example:**
```bash
# Add location
GEOADD restaurants -122.4194 37.7749 "Restaurant A"

# Find nearby (uses geohash internally!)
GEOSEARCH restaurants FROMLONLAT -122.4194 37.7749 BYRADIUS 5 mi
```

**Pros & Cons:**
```markdown
âœ… Simple to understand and implement
âœ… Leverages existing B-tree infrastructure
âœ… Works in any database (just strings!)
âœ… Efficient prefix matching

âš ï¸  Edge case: Grid boundaries
    â””â”€> Two nearby points on opposite sides of boundary
        have different prefixes
    â””â”€> Must check neighboring geohashes

Best for: General proximity search, Redis, MongoDB
```

#### Approach 2: Quadtree

**Structure:**
```markdown
Recursive Space Subdivision:

Initial State:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                â”‚
â”‚   All space    â”‚
â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After subdivision (points A-F):
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”
â”‚    â”‚ C  â”‚
â”‚ A  â”œâ”€â”€â”¬â”€â”¤
â”‚    â”‚B â”‚Dâ”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”´â”€â”¤
â”‚    â”‚    â”‚
â”‚ E  â”‚ F  â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜

Tree Structure:
        Root
       /  |  \  \
      A   B   C   D
     / \     / \
    E   F  ...

Rules:
â”œâ”€> Split when node has > threshold points (4-8)
â”œâ”€> Max depth limit
â””â”€> Adaptive resolution (dense areas = more splits)
```

**Search Algorithm:**
```markdown
Finding points within radius:

1. Navigate to target quadrant (O(log n))
2. Check current quadrant
3. Check neighboring quadrants
4. Expand search radius if needed (move up tree)

Example: Find restaurants near point P
        Root
       /    \
    [Has P] [Check if overlaps]
      /  \
  [Search][Skip]
```

**Pros & Cons:**
```markdown
âœ… Adaptive resolution
âœ… Good for sparse datasets
âœ… Conceptually simple

âŒ Not common in production databases
âŒ Requires custom implementation
âš ï¸  Performance depends on data distribution

Note: Quadtrees influenced modern spatial indexes
      but are largely replaced by R-trees
```

#### Approach 3: R-Tree (Production Standard)

**Key Difference from Quadtree:**
```markdown
Quadtree:
â”œâ”€> Fixed grid subdivision
â”œâ”€> Rigid quadrants
â””â”€> Data-independent structure

R-tree:
â”œâ”€> Flexible, overlapping rectangles
â”œâ”€> Adapts to actual data distribution
â””â”€> Can index both points AND shapes!
```

**Structure:**
```markdown
Hierarchical Bounding Boxes:

Level 1 (Large areas):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  San Francisco   â”‚  Oakland      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚      â”‚        â”‚  â”‚      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜        â”‚  â””â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Level 2 (Neighborhoods):
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚Missionâ”‚SOMA â”‚  â† These can overlap!
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚Marinaâ”‚Haightâ”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜

Level 3 (Individual locations):
â— Restaurant 1
â— Restaurant 2
```

**Search Algorithm:**
```markdown
Query: Restaurants within 5 miles of point P

1. Start at root
2. Check which rectangles overlap search circle
3. Recursively search those branches
4. At leaves, check actual distances

Optimization:
â””â”€> Rectangles minimize overlap to reduce false paths
```

**Real-World Usage:**
```sql
-- PostgreSQL with PostGIS
CREATE TABLE restaurants (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255),
    location GEOGRAPHY(POINT, 4326)  -- WGS84
);

-- R-tree index (automatic with GIST)
CREATE INDEX idx_location ON restaurants USING GIST(location);

-- Query (uses R-tree!)
SELECT name
FROM restaurants
WHERE ST_DWithin(
    location,
    ST_MakePoint(-122.4194, 37.7749)::geography,
    5000  -- 5km
);
```

**Why R-trees Won:**
```markdown
Advantages:
â”œâ”€ Handles points AND shapes (polygons, lines)
â”œâ”€ Flexible rectangles adapt to data
â”œâ”€ Optimized for disk I/O patterns
â”œâ”€ Production-tested (PostGIS, MySQL)
â””â”€> Default in modern spatial databases

Trade-offs:
â””â”€> Overlapping rectangles may require multiple branch searches
    But smart algorithms minimize this
```

---

### Geospatial Index Comparison

```markdown
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Geospatial Index Comparison                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  Feature      â”‚ Geohash  â”‚ Quadtree  â”‚ R-tree    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚               â”‚          â”‚           â”‚           â”‚
â”‚  Approach     â”‚ Hash     â”‚ Tree      â”‚ Tree      â”‚
â”‚  Structure    â”‚ 1D stringâ”‚ Fixed gridâ”‚ Flexible  â”‚
â”‚  Database     â”‚ Any (str)â”‚ Custom    â”‚ PostGIS   â”‚
â”‚  Points       â”‚ âœ…       â”‚ âœ…        â”‚ âœ…        â”‚
â”‚  Shapes       â”‚ âŒ       â”‚ âš ï¸        â”‚ âœ…        â”‚
â”‚  Overlapping  â”‚ N/A      â”‚ No        â”‚ Yes       â”‚
â”‚  Production   â”‚ Common   â”‚ Rare      â”‚ Standard  â”‚
â”‚               â”‚          â”‚           â”‚           â”‚
â”‚  Best for:    â”‚ Simple   â”‚ Learning  â”‚ Productionâ”‚
â”‚               â”‚ proximityâ”‚ concept   â”‚ spatial   â”‚
â”‚               â”‚ search   â”‚           â”‚ databases â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Interview Answer Template:**
```markdown
"Traditional indexes like B-trees treat latitude and longitude
as independent dimensions, which doesn't work for spatial queries.

Two main approaches:

1. Hash-based (Geohash):
   â””â”€> Convert 2D coordinates to 1D string preserving proximity
   â””â”€> Use regular B-tree on geohash strings
   â””â”€> Simple, works in any database

2. Tree-based (R-tree):
   â””â”€> Hierarchical bounding boxes
   â””â”€> Flexible, overlapping rectangles
   â””â”€> Can index both points and shapes
   â””â”€> Standard in production (PostGIS, MySQL)

For most applications, I'd start with geohash for simplicity,
or use R-tree if already using PostGIS/spatial database."

Time: 1-2 minutes
```

---

### 5. Inverted Indexes (Full-Text Search)

**The Problem:**
```sql
-- Pattern matching anywhere in text
SELECT * FROM posts WHERE content LIKE '%database%';

Problem:
â”œâ”€> B-tree can't help (not a prefix match)
â”œâ”€> Must scan every character of every post
â”œâ”€> O(n Ã— m) where n=rows, m=content length
â””â”€> Exponentially slower as content grows! ğŸ˜±
```

**Solution: Inverted Index**
```markdown
Traditional (Document â†’ Words):
doc1: "B-trees are fast and reliable"
doc2: "Hash tables are fast but limited"

Inverted (Word â†’ Documents):
b-trees  â†’ [doc1]
fast     â†’ [doc1, doc2]
reliable â†’ [doc1]
hash     â†’ [doc2]
tables   â†’ [doc2]
limited  â†’ [doc2]

Query "fast" â†’ [doc1, doc2] in O(1)!
```

**How It Works:**
```markdown
Indexing Pipeline:

1. Tokenization
   "B-trees are FAST!" â†’ ["B", "trees", "are", "FAST"]

2. Normalization
   ["B", "trees", "are", "FAST"] â†’ ["b", "trees", "fast"]

3. Stop Words Removal
   ["b", "trees", "fast"] â†’ ["trees", "fast"]
   (remove common words: "the", "are", "is")

4. Stemming
   ["trees", "fast"] â†’ ["tree", "fast"]
   (reduce to root form)

5. Build Index
   tree â†’ [doc1, doc3, doc5]
   fast â†’ [doc1, doc2, doc7]

Advanced Features:
â”œâ”€ Term frequency (how often word appears)
â”œâ”€ Relevance scoring (best matches first)
â”œâ”€ Fuzzy matching ("databas" matches "database")
â””â”€ Phrase queries ("machine learning" as exact phrase)
```

**Real-World Examples:**
```markdown
Elasticsearch:
POST /posts/_doc/1
{
  "title": "Database Indexing",
  "content": "B-trees are the default index type"
}

# Automatic inverted index creation
# Query:
GET /posts/_search
{
  "query": {
    "match": {
      "content": "database index"  # Matches "Database Indexing"!
    }
  }
}

Other Examples:
â”œâ”€ GitHub code search
â”œâ”€ Slack message search
â”œâ”€ Google Docs search
â””â”€> Any text search uses inverted indexes!
```

**Trade-offs:**
```markdown
âœ… Benefits:
â”œâ”€ Fast text search (milliseconds)
â”œâ”€ Natural language queries
â”œâ”€ Relevance ranking
â””â”€> Fuzzy/synonym matching

âŒ Costs:
â”œâ”€ Large storage overhead (100-200% of original)
â”œâ”€ Expensive updates (re-index many terms)
â”œâ”€ Complex analysis pipeline
â””â”€> Need specialized systems (Elasticsearch, Lucene)

Best for: Full-text search, logs, documents
```

---

## Optimization Patterns

### 1. Composite Indexes

**Problem:**
```sql
-- Typical social media query
SELECT * FROM posts
WHERE user_id = 123
  AND created_at > '2024-01-01'
ORDER BY created_at DESC;

-- Naive approach (two indexes):
CREATE INDEX idx_user ON posts(user_id);
CREATE INDEX idx_time ON posts(created_at);

Execution:
â”œâ”€ Use idx_user â†’ Find all posts by user 123 (maybe 1000 rows)
â”œâ”€ Use idx_time â†’ Find all posts after date (maybe 100K rows)
â”œâ”€ Intersect results (expensive!)
â””â”€> Sort final results by created_at (expensive!)
```

**Solution: Composite Index**
```sql
-- One index, multiple columns
CREATE INDEX idx_user_time ON posts(user_id, created_at);

B-tree Structure:
(1, 2024-01-01)  â—„â”€â”€ User 1's posts, sorted by time
(1, 2024-01-02)
(1, 2024-01-03)
(2, 2024-01-01)  â—„â”€â”€ User 2's posts, sorted by time
(2, 2024-01-02)
(3, 2024-01-01)

Execution:
â”œâ”€ Find first entry for user_id=123
â”œâ”€ Scan sequentially until created_at > date
â””â”€> Already sorted! No extra work needed! âœ…
```

**Column Order Matters:**
```markdown
Index: (user_id, created_at)

âœ… Can efficiently answer:
â”œâ”€ WHERE user_id = 123
â”œâ”€ WHERE user_id = 123 AND created_at > date
â””â”€> WHERE user_id = 123 ORDER BY created_at

âŒ Cannot efficiently answer:
â”œâ”€ WHERE created_at > date (wrong prefix)
â””â”€> ORDER BY created_at (needs user_id first)

Rule: Order columns from most selective to least
      OR based on query patterns (filter â†’ sort)
```

**Common Patterns:**
```sql
-- E-commerce orders
CREATE INDEX idx_customer_date ON orders(customer_id, order_date);
-- Query: "Show my recent orders"

-- Event processing
CREATE INDEX idx_status_priority ON events(status, priority, created_at);
-- Query: "Process pending high-priority events"

-- Activity feeds
CREATE INDEX idx_user_type_time ON activities(user_id, type, timestamp);
-- Query: "Show user's likes, sorted by time"
```

---

### 2. Covering Indexes

**Problem:**
```sql
-- Social feed query
SELECT user_id, created_at, likes
FROM posts
WHERE user_id = 123
ORDER BY created_at DESC;

-- With regular index
CREATE INDEX idx_user_time ON posts(user_id, created_at);

Execution:
â”œâ”€ Traverse index to find matching posts
â”œâ”€ For each post_id found in index:
â”‚   â””â”€> Read full row from table to get 'likes' column ğŸ˜±
â”œâ”€ If 20 posts â†’ 20 additional disk reads!
â””â”€> Slow for large result sets
```

**Solution: Include Extra Columns**
```sql
-- Covering index (PostgreSQL)
CREATE INDEX idx_user_time_likes
ON posts(user_id, created_at) INCLUDE (likes);

Execution:
â”œâ”€ Traverse index
â”œâ”€ Index contains ALL needed columns!
â””â”€> Return results directly from index âœ…
    No table lookups needed!
```

**When to Use:**
```markdown
âœ… Good scenarios:
â”œâ”€ Query frequently-run, only needs few columns
â”œâ”€ Read-heavy workload
â”œâ”€ Column values small (integers, not TEXT)
â””â”€> Performance critical (leaderboards, feeds)

âŒ Avoid when:
â”œâ”€ Table has frequent writes (index maintenance cost)
â”œâ”€ Included columns are large (bloats index)
â”œâ”€ Many different query patterns (can't cover all)
â””â”€> Query optimizer already efficient

Reality in 2025:
â””â”€> Modern optimizers are smart
    Covering indexes are niche optimization
    Focus on simpler strategies first!
```

**Example:**
```sql
-- Leaderboard query (frequently run)
SELECT username, score
FROM users
WHERE game_id = 1
ORDER BY score DESC
LIMIT 10;

-- Covering index
CREATE INDEX idx_game_score
ON users(game_id, score DESC) INCLUDE (username);
-- Returns top 10 purely from index!
```

---

### 3. Partial Indexes

**Concept:**
```sql
-- Index only subset of rows
CREATE INDEX idx_active_users
ON users(username)
WHERE active = true;

Benefits:
â”œâ”€ Smaller index size
â”œâ”€ Faster to update
â””â”€> Still fast for filtered queries!
```

**When to Use:**
```markdown
Scenarios:
â”œâ”€ Most queries filter on same condition
â”‚   Example: "WHERE status = 'active'"
â”‚
â”œâ”€ Small subset of data accessed frequently
â”‚   Example: 90% of orders are 'completed'
â”‚              Only 10% are 'pending' (what we query)
â”‚
â””â”€> Save space and maintenance cost!
```

---

## Interview Templates

### Template 1: When to Add Index

```markdown
Interviewer: "How do you decide which columns to index?"

You:
"I look at the query patterns first. Indexes are most valuable for:

1. WHERE clause columns
   â””â”€> Filtering large result sets

2. JOIN columns
   â””â”€> Both sides of the join

3. ORDER BY columns
   â””â”€> Avoid expensive sorting

4. Frequently queried columns
   â””â”€> Based on access patterns from APIs

For example, in a Twitter-like system:
â”œâ”€ tweets(user_id) - for 'show user's tweets'
â”œâ”€ tweets(user_id, created_at) - composite for timeline
â””â”€> likes(tweet_id) - for counting likes

I avoid indexing:
â”œâ”€ Small tables (< 1000 rows)
â”œâ”€ Low cardinality columns (gender, boolean)
â”œâ”€ Columns rarely queried
â””â”€> Write-heavy tables with infrequent reads

The goal is balance: fast queries without write penalties."

Time: 1-2 minutes
```

### Template 2: Index Type Selection

```markdown
Interviewer: "What type of index would you use?"

You:
"Default to B-trees - they handle both exact matches and range queries.

But there are specialized cases:

1. Geospatial queries (nearby restaurants)
   â””â”€> Use geospatial index (geohash or R-tree)
   â””â”€> Because lat/long need 2D proximity search

2. Full-text search (search blog posts)
   â””â”€> Use inverted index (Elasticsearch)
   â””â”€> Because pattern matching anywhere in text

3. Write-heavy workloads (logging, metrics)
   â””â”€> Consider LSM-tree database (Cassandra)
   â””â”€> Because batched writes are 10-100x faster

4. Exact-match only, in-memory
   â””â”€> Maybe hash index (Redis)
   â””â”€> But B-trees usually fine too

For 90% of cases, B-tree is the right answer."

Time: 1-2 minutes
```

### Template 3: Composite Index Design

```markdown
Interviewer: "How would you index this query?"

Query:
SELECT * FROM orders
WHERE customer_id = 123
  AND status = 'shipped'
ORDER BY order_date DESC;

You:
"I'd create a composite index on (customer_id, status, order_date):

CREATE INDEX idx_orders
ON orders(customer_id, status, order_date DESC);

Column order matters:
1. customer_id first - most selective, always in WHERE
2. status second - also in WHERE clause
3. order_date last - used for ORDER BY

This single index handles:
â”œâ”€ Filtering by customer
â”œâ”€ Filtering by status
â””â”€> Sorting by date (no extra sort needed!)

The database can:
â”œâ”€ Seek to customer 123
â”œâ”€ Scan entries matching status
â””â”€> Results already in date order âœ…

Alternative approach: If we mostly query just by customer_id,
I might do (customer_id, order_date) to keep index smaller."

Time: 1-2 minutes
```

### Template 4: Geospatial Indexing

```markdown
Interviewer: "How would you find nearby restaurants?"

You:
"Regular B-trees don't work well for this because they treat
latitude and longitude as independent dimensions. We need an
index that understands 2D spatial relationships.

Two main approaches:

1. Geohash (simpler):
   â”œâ”€ Convert lat/lng to 1D string: 'dr5ru7'
   â”œâ”€ Nearby locations share prefix
   â”œâ”€ Use regular B-tree on geohash strings
   â””â”€> Works in any database (Redis, MongoDB)

2. R-tree (more powerful):
   â”œâ”€ Hierarchical bounding boxes
   â”œâ”€ Flexible, overlapping rectangles
   â”œâ”€ Handles shapes (not just points)
   â””â”€> Standard in PostGIS, MySQL spatial

For most applications, geohash is sufficient:
CREATE INDEX idx_geohash ON restaurants(geohash);

Query nearby:
SELECT * FROM restaurants
WHERE geohash BETWEEN 'dr5ru' AND 'dr5ru~';

Then filter exact distances in application code."

Time: 2 minutes
```

---

## Quick Reference

### Decision Flowchart

```markdown
Need to optimize query?
    â”‚
    â”œâ”€> Exact match only? (id = 123)
    â”‚   â””â”€> B-tree âœ… (default)
    â”‚
    â”œâ”€> Range queries? (age > 25)
    â”‚   â””â”€> B-tree âœ…
    â”‚
    â”œâ”€> Sorting? (ORDER BY created_at)
    â”‚   â””â”€> B-tree âœ… or Composite
    â”‚
    â”œâ”€> Location search? (nearby restaurants)
    â”‚   â””â”€> Geospatial (geohash or R-tree)
    â”‚
    â”œâ”€> Full-text search? (content LIKE '%word%')
    â”‚   â””â”€> Inverted index (Elasticsearch)
    â”‚
    â”œâ”€> Write-heavy? (millions of inserts/sec)
    â”‚   â””â”€> LSM-tree (Cassandra, RocksDB)
    â”‚
    â””â”€> Multiple columns in WHERE/ORDER BY?
        â””â”€> Composite index

When in doubt: B-tree! ğŸ¯
```

### Performance Numbers

```markdown
Operation                    | Time (Approximate)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
B-tree lookup               | 1-10ms (2-3 disk reads)
Full table scan (1M rows)   | 1-5 seconds
Hash index lookup           | 1-5ms (O(1))
Geohash proximity search    | 10-50ms
R-tree spatial query        | 20-100ms
Inverted index text search  | 10-100ms
LSM tree write              | 0.1-1ms (buffered)
B-tree write                | 5-20ms (immediate)

Rule of thumb:
â”œâ”€ Index improves reads: 100-1000x
â”œâ”€ Index slows writes: 2-5x
â””â”€> Worth it for read-heavy workloads!
```

### Common Mistakes

```markdown
âŒ DON'T:
â”œâ”€ Index every column "just in case"
â”œâ”€ Create hash indexes by default
â”œâ”€ Ignore write performance impact
â”œâ”€ Use LIKE '%pattern%' and expect index help
â”œâ”€ Index small tables (< 1000 rows)
â””â”€> Forget to maintain indexes (VACUUM, ANALYZE)

âœ… DO:
â”œâ”€ Start with B-trees
â”œâ”€ Profile queries first (EXPLAIN)
â”œâ”€ Index based on access patterns
â”œâ”€ Use composite indexes for multi-column queries
â”œâ”€ Monitor slow query logs
â””â”€> Remove unused indexes periodically
```

### Pre-Interview Checklist

```markdown
Core Concepts:
â–¡ Understand why indexes exist (minimize disk reads)
â–¡ Know trade-offs (fast reads, slow writes, storage)
â–¡ Can explain B-tree structure and traversal

Index Types:
â–¡ B-tree: Default choice, versatile
â–¡ LSM: Write-heavy workloads
â–¡ Hash: Rarely used (know why!)
â–¡ Geospatial: Location queries
â–¡ Inverted: Full-text search

Optimization:
â–¡ Composite indexes (column order matters)
â–¡ Covering indexes (niche optimization)
â–¡ When to avoid indexes

Interview Strategy:
â–¡ Always ask about access patterns first
â–¡ Default to B-trees unless special case
â–¡ Explain trade-offs clearly
â–¡ Know 1-2 real-world examples per type
```

---

## Practice Scenarios

### Scenario 1: Twitter Timeline

**Requirements:**
- Show user's feed (tweets from followed users)
- Sort by most recent
- 1 million tweets per user

**Schema:**
```sql
CREATE TABLE tweets (
    id BIGINT PRIMARY KEY,
    user_id BIGINT,
    content TEXT,
    created_at TIMESTAMP
);

CREATE TABLE follows (
    follower_id BIGINT,
    followee_id BIGINT,
    PRIMARY KEY (follower_id, followee_id)
);
```

**Indexes Needed:**
```sql
-- For feed query
CREATE INDEX idx_tweets_user_time
ON tweets(user_id, created_at DESC);

-- For follow lookup
CREATE INDEX idx_follows_followee
ON follows(followee_id);

-- For user's own tweets
CREATE INDEX idx_tweets_user
ON tweets(user_id);

Query:
SELECT t.*
FROM tweets t
JOIN follows f ON t.user_id = f.followee_id
WHERE f.follower_id = 123
ORDER BY t.created_at DESC
LIMIT 20;
```

---

### Scenario 2: Uber Driver Matching

**Requirements:**
- Find nearby drivers (within 5km)
- Consider driver status (available/busy)
- Real-time updates (millions/sec)

**Schema:**
```sql
CREATE TABLE drivers (
    id BIGINT PRIMARY KEY,
    name VARCHAR(255),
    status VARCHAR(20),
    latitude DECIMAL(10, 8),
    longitude DECIMAL(11, 8),
    geohash VARCHAR(12),
    updated_at TIMESTAMP
);
```

**Indexes Needed:**
```sql
-- Geospatial for proximity
CREATE INDEX idx_geohash_status
ON drivers(geohash, status);

-- Or use PostGIS
CREATE INDEX idx_location
ON drivers USING GIST(ST_MakePoint(longitude, latitude));

Query:
SELECT *
FROM drivers
WHERE geohash BETWEEN 'dr5ru' AND 'dr5ru~'
  AND status = 'available'
  AND updated_at > NOW() - INTERVAL '1 minute'
ORDER BY ST_Distance(location, rider_location)
LIMIT 10;
```

---

### Scenario 3: E-commerce Product Search

**Requirements:**
- Full-text search in product names/descriptions
- Filter by category, price range
- Sort by relevance or price

**Schema:**
```sql
CREATE TABLE products (
    id BIGINT PRIMARY KEY,
    name VARCHAR(255),
    description TEXT,
    category_id INT,
    price DECIMAL(10, 2),
    created_at TIMESTAMP
);
```

**Indexes Needed:**
```sql
-- Full-text search (PostgreSQL)
CREATE INDEX idx_search
ON products USING GIN(to_tsvector('english', name || ' ' || description));

-- Category + price (composite)
CREATE INDEX idx_category_price
ON products(category_id, price);

-- Or use Elasticsearch
POST /products/_doc/1
{
  "name": "iPhone 15",
  "description": "Latest smartphone",
  "category": "Electronics",
  "price": 999
}

Query (Elasticsearch):
GET /products/_search
{
  "query": {
    "bool": {
      "must": { "match": { "name": "phone" } },
      "filter": [
        { "term": { "category": "Electronics" } },
        { "range": { "price": { "lte": 1000 } } }
      ]
    }
  },
  "sort": [ { "_score": "desc" } ]
}
```

---

## Final Tips

```markdown
Interview Strategy:

1. Clarify Requirements First
   â”œâ”€ Read or write heavy?
   â”œâ”€ Query patterns?
   â””â”€> Scale (rows, queries/sec)?

2. Start Simple
   â”œâ”€ B-tree for most cases
   â””â”€> Explain why it works

3. Identify Special Cases
   â”œâ”€ Location? â†’ Geospatial
   â”œâ”€ Text search? â†’ Inverted
   â”œâ”€ Write-heavy? â†’ LSM
   â””â”€> Explain trade-offs

4. Consider Optimization
   â”œâ”€ Composite for multi-column
   â”œâ”€ Covering if frequently-run
   â””â”€> But don't over-engineer!

5. Discuss Monitoring
   â”œâ”€ Slow query logs
   â”œâ”€ Index usage stats
   â””â”€> Remove unused indexes

Remember:
"There's no perfect answer. Show your reasoning!"

Key soundbites:
â”œâ”€ "B-trees are the default because they're versatile"
â”œâ”€ "Indexes trade storage and write speed for read speed"
â”œâ”€ "Column order matters in composite indexes"
â””â”€> "Always profile before optimizing"
```

---

Good luck with your interviews! ğŸš€

**Most Important Takeaways:**
1. **B-trees are default** - versatile, handle 90% of cases
2. **Know the trade-offs** - fast reads vs slow writes
3. **Access patterns drive decisions** - analyze queries first
4. **Composite indexes** - powerful for multi-column queries
5. **Special cases** - geospatial (location), inverted (text), LSM (writes)<!-- filepath: /workspaces/abhaysrivastav.github.io/blogs/database-index.md -->
---
layout: default
title: Database Indexing - Interview Notes
---

# Database Indexing - Interview Notes ğŸ“š

## Table of Contents
1. [Core Concepts](#core-concepts)
2. [Index Types](#index-types)
3. [Optimization Patterns](#optimization-patterns)
4. [Interview Templates](#interview-templates)
5. [Quick Reference](#quick-reference)

---

## Core Concepts

### What is an Index?

```markdown
Problem:
â””â”€> Finding data without index = Full table scan
    "Search through every book in library one by one"

Solution:
â””â”€> Index = Separate data structure optimized for searching
    "Like index at back of textbook - jump directly to page"

Key Insight:
â”œâ”€> Indexes minimize disk reads
â”œâ”€> Transform random access to structured path
â””â”€> Trade storage space for query speed
```

### How Databases Store Data

```markdown
Without Index (Heap File):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rows stored in no particular order     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚ â”‚ id â”‚ username â”‚     email      â”‚     â”‚
â”‚ â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚ â”‚ 5  â”‚ raj      â”‚ raj@mail.com   â”‚     â”‚
â”‚ â”‚ 1  â”‚ abhay    â”‚ abhay@mail.com â”‚     â”‚
â”‚ â”‚ 3  â”‚ priya    â”‚ priya@mail.com â”‚     â”‚
â”‚ â”‚ 2  â”‚ amit     â”‚ amit@mail.com  â”‚     â”‚
â”‚ â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                        â”‚
â”‚ Query: SELECT * WHERE id = 3           â”‚
â”‚ â””â”€> Must scan ALL rows! ğŸ˜±             â”‚
â”‚     Time: O(n) - Very slow!            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

With Index (B-tree):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Index maintains sorted structure       â”‚
â”‚        Root: [5]                       â”‚
â”‚       /         \                      â”‚
â”‚    [1, 3]      [10, 15]                â”‚
â”‚                                        â”‚
â”‚ Query: SELECT * WHERE id = 3           â”‚
â”‚ â””â”€> Traverse tree: Rootâ†’Leftâ†’Found âœ…  â”‚
â”‚     Time: O(log n) - Fast!             â”‚
â”‚     Disk reads: 2-3 pages only         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Index Trade-offs

```markdown
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Benefits vs Costs                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  âœ… Benefits:                                      â”‚
â”‚  â”œâ”€ Fast reads (100-1000x improvement)             â”‚
â”‚  â”œâ”€ Efficient range queries                        â”‚
â”‚  â”œâ”€ Support for sorting (ORDER BY)                 â”‚
â”‚  â””â”€ Enable unique constraints                      â”‚
â”‚                                                    â”‚
â”‚  âŒ Costs:                                         â”‚
â”‚  â”œâ”€ Extra disk space (sometimes = table size)      â”‚
â”‚  â”œâ”€ Slower writes (update index + table)           â”‚
â”‚  â”œâ”€ Memory overhead (buffer pool pressure)         â”‚
â”‚  â””â”€ Maintenance complexity                         â”‚
â”‚                                                    â”‚
â”‚  When Indexes Hurt:                                â”‚
â”‚  â”œâ”€ Small tables (< 1000 rows)                     â”‚
â”‚  â”œâ”€ Write-heavy workloads (logging, metrics)       â”‚
â”‚  â”œâ”€ Low cardinality columns (gender, status)       â”‚
â”‚  â””â”€ Too many indexes (every write updates all)     â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Index Types

### 1. B-Tree Indexes (Default Choice)

**Structure:**
```markdown
B-tree Node Structure:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [key1 | ptr1 | key2 | ptr2 | key3] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚              â”‚
        â–¼              â–¼              â–¼
   Child nodes or leaf data

Properties:
â”œâ”€ Self-balancing (all leaves same depth)
â”œâ”€ Sorted keys within each node
â”œâ”€ Node size = Disk page size (8KB typical)
â””â”€ M-way tree (hundreds of children per node)

Example: Finding id=350
     [100, 500]           â—„â”€â”€ Root (1 disk read)
      /        \
  [50,150]   [300,400]    â—„â”€â”€ Internal (1 disk read)
              /      \
        [350,375] [425,450] â—„â”€â”€ Leaf (1 disk read)
                 â–²
            Found it! (3 total disk reads)
```

**When to Use:**
```sql
-- Perfect for B-tree:
SELECT * FROM users WHERE id = 123;           -- Equality
SELECT * FROM posts WHERE created_at > '2024-01-01'; -- Range
SELECT * FROM users ORDER BY username;        -- Sorting
SELECT * FROM tweets WHERE user_id IN (1,2,3); -- Multiple values

-- Create B-tree index (default):
CREATE INDEX idx_users_email ON users(email);
```

**Real-World Examples:**
```markdown
PostgreSQL:
â”œâ”€ Primary keys â†’ B-tree (automatic)
â”œâ”€ Unique constraints â†’ B-tree (automatic)
â””â”€ Default index type for CREATE INDEX

MongoDB:
â”œâ”€ _id field â†’ B-tree (automatic)
â””â”€> db.users.createIndex({ email: 1 })

MySQL (InnoDB):
â””â”€> Uses B+tree variant (all data in leaves)
```

**Strengths:**
```markdown
âœ… Balanced workloads (reads + writes)
âœ… Range queries (age > 25, date BETWEEN)
âœ… Sorting (ORDER BY efficient)
âœ… Prefix matching (email LIKE 'abc%')
âœ… Predictable O(log n) performance
```

---

### 2. LSM Trees (Write-Heavy Workloads)

**Problem B-trees Solve Poorly:**
```markdown
Write-Heavy Scenario:
â””â”€> DataDog ingesting 100,000 metrics/second

B-tree Bottleneck:
â”œâ”€> Each write = Find leaf + Read page + Update + Write back
â”œâ”€> Random disk seeks kill performance
â””â”€> Time: 10ms per write â†’ Can't keep up! ğŸ˜±

LSM Solution:
â”œâ”€> Batch writes in memory
â”œâ”€> Flush sequentially to disk
â””â”€> Time: 0.1ms per write â†’ 100x faster! âœ…
```

**How LSM Trees Work:**
```markdown
Write Path:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Memtable (In-Memory)                â”‚
â”‚    â””â”€> Red-black tree or skip list     â”‚
â”‚        Insert: O(log n) in RAM         â”‚
â”‚                                        â”‚
â”‚ 2. Write-Ahead Log (WAL)               â”‚
â”‚    â””â”€> Sequential append to disk       â”‚
â”‚        Ensures durability              â”‚
â”‚                                        â”‚
â”‚ 3. Flush to SSTable (Immutable)        â”‚
â”‚    â””â”€> When memtable full (~4MB)       â”‚
â”‚        Sequential write (very fast!)   â”‚
â”‚                                        â”‚
â”‚ 4. Compaction (Background)             â”‚
â”‚    â””â”€> Merge SSTables periodically     â”‚
â”‚        Remove duplicates/deletes       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Storage on Disk:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memtable (current, in RAM)            â”‚
â”‚  â”œâ”€ key1: value1                       â”‚
â”‚  â”œâ”€ key2: value2                       â”‚
â”‚  â””â”€ key3: value3                       â”‚
â”‚                                        â”‚
â”‚  SSTable-4 (newest, on disk)           â”‚
â”‚  SSTable-3                             â”‚
â”‚  SSTable-2                             â”‚
â”‚  SSTable-1 (oldest)                    â”‚
â”‚                                        â”‚
â”‚  Write = Append to memtable âœ…         â”‚
â”‚  Read = Check all layers ğŸ˜±            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Read Optimization:**
```markdown
Problem: Multiple SSTables to check

Solutions:
â”œâ”€ Bloom Filters
â”‚  â””â”€> "Is key definitely NOT in this file?"
â”‚      95% of SSTables skipped!
â”‚
â”œâ”€ Sparse Index
â”‚  â””â”€> Range check: Does SSTable contain key range?
â”‚      Skip entire files
â”‚
â””â”€ Compaction Strategy
   â”œâ”€ Size-tiered: Few files, more overlap
   â””â”€ Leveled: More files, less overlap
```

**Performance Comparison:**
```markdown
Operation          | B-tree  | LSM-tree
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Write (single)     | 10ms    | 0.1ms âœ…
Read (point query) | 5ms     | 20ms âš ï¸
Range scan         | 10ms    | 30ms âš ï¸
Bulk write         | Slow    | Fast âœ…

Conclusion:
â”œâ”€ LSM = Write-optimized (10-100x faster writes)
â””â”€ B-tree = Read-optimized (2-5x faster reads)
```

**Real-World Examples:**
```markdown
Cassandra:
â””â”€> Netflix viewing events (billions/day)

RocksDB:
â””â”€> Facebook social interactions (millions/sec)

DynamoDB:
â””â”€> LSM-style architecture for high write throughput

Use Cases:
â”œâ”€ Time-series data (metrics, logs)
â”œâ”€ Event streaming (Kafka, analytics)
â”œâ”€ IoT data ingestion
â””â”€ Write-heavy applications (90:10 write:read)
```

---

### 3. Hash Indexes (Exact Match Only)

**Structure:**
```markdown
Hash Index = Persistent HashMap

Example:
buckets[hash("alice@example.com")] â†’ ptr to page 1
buckets[hash("bob@example.com")]   â†’ ptr to page 2
buckets[hash("charlie@example.com")] â†’ ptr to page 1 (collision!)

Collision Handling:
â””â”€> Chaining (linked list in bucket)
    Or overflow pages

Performance:
â”œâ”€ Exact match: O(1) âœ…
â”œâ”€ Range query: Impossible âŒ
â””â”€> Sorting: Impossible âŒ
```

**When to Use:**
```sql
-- Good for hash index:
SELECT * FROM users WHERE email = 'exact@match.com';

-- Bad for hash index:
SELECT * FROM users WHERE email LIKE 'abc%';  -- âŒ
SELECT * FROM users WHERE age > 25;           -- âŒ
SELECT * FROM users ORDER BY email;           -- âŒ

-- Create hash index (PostgreSQL):
CREATE INDEX idx_email_hash ON users USING HASH(email);
```

**Reality Check:**
```markdown
Why Hash Indexes are Rare:

B-tree vs Hash for exact match:
â”œâ”€ Hash: O(1) â†’ 1-2 disk reads
â”œâ”€ B-tree: O(log n) â†’ 2-3 disk reads
â””â”€> Difference: Negligible in practice!

B-tree advantages:
â”œâ”€ Also supports range queries âœ…
â”œâ”€ Also supports sorting âœ…
â”œâ”€ Smaller size (better compression)
â””â”€> More versatile!

When Hash Wins:
â”œâ”€ In-memory databases (Redis)
â”œâ”€ MySQL MEMORY engine (deprecated)
â””â”€> When range queries NEVER needed
```

**Interview Tip:**
```markdown
âŒ Don't overemphasize hash indexes

Better answer:
"For exact matches, B-trees perform nearly as well as hash indexes
 while also supporting range queries and sorting. I'd default to
 B-trees unless I have a specific reason to use hash indexes,
 like an in-memory cache where exact-match performance is critical."

Focusing too much on hash indexes might seem out of touch! ğŸ˜…
```

---

### 4. Geospatial Indexes

**The Problem:**
```markdown
Scenario: Find restaurants within 5 miles

Naive Approach:
CREATE INDEX idx_lat ON restaurants(latitude);
CREATE INDEX idx_lng ON restaurants(longitude);

Query:
SELECT * FROM restaurants
WHERE latitude BETWEEN 37.7 AND 37.8
  AND longitude BETWEEN -122.5 AND -122.4;

Problem:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Search Rectangle               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Too many false positives!        â”‚  â”‚
â”‚  â”‚                                  â”‚  â”‚
â”‚  â”‚         â— Actual circle          â”‚  â”‚
â”‚  â”‚        â— â— search area           â”‚  â”‚
â”‚  â”‚       â—   â—                      â”‚  â”‚
â”‚  â”‚        â— â—                       â”‚  â”‚
â”‚  â”‚         â—                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                        â”‚
â”‚ Rectangle includes distant corners!    â”‚
â”‚ Need to filter out ~40% of results ğŸ˜±  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Need: Index that understands 2D proximity!
```

#### Approach 1: Geohash

**How it Works:**
```markdown
Concept: Convert 2D â†’ 1D string preserving proximity

Process:
1. Divide world into 4 quadrants (00, 01, 10, 11)
2. Subdivide each quadrant into 4 more
3. Continue until desired precision
4. Encode as base32 string

Example:
"dr" â†’ San Francisco (city)
"dr5" â†’ Mission District (neighborhood)
"dr5ru" â†’ Specific block (100m precision)
"dr5ru7" â†’ Building (25m precision)

Key Property:
â”œâ”€> Nearby locations share prefix
â”œâ”€> "dr5ru123" and "dr5ru456" are close!
â””â”€> Can use B-tree on geohash strings!
```

**Implementation:**
```sql
-- PostgreSQL/PostGIS
CREATE TABLE restaurants (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255),
    latitude DECIMAL(10, 8),
    longitude DECIMAL(11, 8),
    geohash VARCHAR(12)  -- Generated column
);

CREATE INDEX idx_geohash ON restaurants(geohash);

-- Query nearby (B-tree range scan!)
SELECT * FROM restaurants
WHERE geohash BETWEEN 'dr5ru' AND 'dr5ru~'
  AND ST_Distance(point, target) < 5000;  -- Final filter
```

**Redis Example:**
```bash
# Add location
GEOADD restaurants -122.4194 37.7749 "Restaurant A"

# Find nearby (uses geohash internally!)
GEOSEARCH restaurants FROMLONLAT -122.4194 37.7749 BYRADIUS 5 mi
```

**Pros & Cons:**
```markdown
âœ… Simple to understand and implement
âœ… Leverages existing B-tree infrastructure
âœ… Works in any database (just strings!)
âœ… Efficient prefix matching

âš ï¸  Edge case: Grid boundaries
    â””â”€> Two nearby points on opposite sides of boundary
        have different prefixes
    â””â”€> Must check neighboring geohashes

Best for: General proximity search, Redis, MongoDB
```

#### Approach 2: Quadtree

**Structure:**
```markdown
Recursive Space Subdivision:

Initial State:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                â”‚
â”‚   All space    â”‚
â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After subdivision (points A-F):
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”
â”‚    â”‚ C  â”‚
â”‚ A  â”œâ”€â”€â”¬â”€â”¤
â”‚    â”‚B â”‚Dâ”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”´â”€â”¤
â”‚    â”‚    â”‚
â”‚ E  â”‚ F  â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜

Tree Structure:
        Root
       /  |  \  \
      A   B   C   D
     / \     / \
    E   F  ...

Rules:
â”œâ”€> Split when node has > threshold points (4-8)
â”œâ”€> Max depth limit
â””â”€> Adaptive resolution (dense areas = more splits)
```

**Search Algorithm:**
```markdown
Finding points within radius:

1. Navigate to target quadrant (O(log n))
2. Check current quadrant
3. Check neighboring quadrants
4. Expand search radius if needed (move up tree)

Example: Find restaurants near point P
        Root
       /    \
    [Has P] [Check if overlaps]
      /  \
  [Search][Skip]
```

**Pros & Cons:**
```markdown
âœ… Adaptive resolution
âœ… Good for sparse datasets
âœ… Conceptually simple

âŒ Not common in production databases
âŒ Requires custom implementation
âš ï¸  Performance depends on data distribution

Note: Quadtrees influenced modern spatial indexes
      but are largely replaced by R-trees
```

#### Approach 3: R-Tree (Production Standard)

**Key Difference from Quadtree:**
```markdown
Quadtree:
â”œâ”€> Fixed grid subdivision
â”œâ”€> Rigid quadrants
â””â”€> Data-independent structure

R-tree:
â”œâ”€> Flexible, overlapping rectangles
â”œâ”€> Adapts to actual data distribution
â””â”€> Can index both points AND shapes!
```

**Structure:**
```markdown
Hierarchical Bounding Boxes:

Level 1 (Large areas):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  San Francisco   â”‚  Oakland      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚      â”‚        â”‚  â”‚      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜        â”‚  â””â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Level 2 (Neighborhoods):
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚Missionâ”‚SOMA â”‚  â† These can overlap!
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚Marinaâ”‚Haightâ”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜

Level 3 (Individual locations):
â— Restaurant 1
â— Restaurant 2
```

**Search Algorithm:**
```markdown
Query: Restaurants within 5 miles of point P

1. Start at root
2. Check which rectangles overlap search circle
3. Recursively search those branches
4. At leaves, check actual distances

Optimization:
â””â”€> Rectangles minimize overlap to reduce false paths
```

**Real-World Usage:**
```sql
-- PostgreSQL with PostGIS
CREATE TABLE restaurants (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255),
    location GEOGRAPHY(POINT, 4326)  -- WGS84
);

-- R-tree index (automatic with GIST)
CREATE INDEX idx_location ON restaurants USING GIST(location);

-- Query (uses R-tree!)
SELECT name
FROM restaurants
WHERE ST_DWithin(
    location,
    ST_MakePoint(-122.4194, 37.7749)::geography,
    5000  -- 5km
);
```

**Why R-trees Won:**
```markdown
Advantages:
â”œâ”€ Handles points AND shapes (polygons, lines)
â”œâ”€ Flexible rectangles adapt to data
â”œâ”€ Optimized for disk I/O patterns
â”œâ”€ Production-tested (PostGIS, MySQL)
â””â”€> Default in modern spatial databases

Trade-offs:
â””â”€> Overlapping rectangles may require multiple branch searches
    But smart algorithms minimize this
```

---

### Geospatial Index Comparison

```markdown
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Geospatial Index Comparison                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  Feature      â”‚ Geohash  â”‚ Quadtree  â”‚ R-tree    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚               â”‚          â”‚           â”‚           â”‚
â”‚  Approach     â”‚ Hash     â”‚ Tree      â”‚ Tree      â”‚
â”‚  Structure    â”‚ 1D stringâ”‚ Fixed gridâ”‚ Flexible  â”‚
â”‚  Database     â”‚ Any (str)â”‚ Custom    â”‚ PostGIS   â”‚
â”‚  Points       â”‚ âœ…       â”‚ âœ…        â”‚ âœ…        â”‚
â”‚  Shapes       â”‚ âŒ       â”‚ âš ï¸        â”‚ âœ…        â”‚
â”‚  Overlapping  â”‚ N/A      â”‚ No        â”‚ Yes       â”‚
â”‚  Production   â”‚ Common   â”‚ Rare      â”‚ Standard  â”‚
â”‚               â”‚          â”‚           â”‚           â”‚
â”‚  Best for:    â”‚ Simple   â”‚ Learning  â”‚ Productionâ”‚
â”‚               â”‚ proximityâ”‚ concept   â”‚ spatial   â”‚
â”‚               â”‚ search   â”‚           â”‚ databases â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Interview Answer Template:**
```markdown
"Traditional indexes like B-trees treat latitude and longitude
as independent dimensions, which doesn't work for spatial queries.

Two main approaches:

1. Hash-based (Geohash):
   â””â”€> Convert 2D coordinates to 1D string preserving proximity
   â””â”€> Use regular B-tree on geohash strings
   â””â”€> Simple, works in any database

2. Tree-based (R-tree):
   â””â”€> Hierarchical bounding boxes
   â””â”€> Flexible, overlapping rectangles
   â””â”€> Can index both points and shapes
   â””â”€> Standard in production (PostGIS, MySQL)

For most applications, I'd start with geohash for simplicity,
or use R-tree if already using PostGIS/spatial database."

Time: 1-2 minutes
```

---

### 5. Inverted Indexes (Full-Text Search)

**The Problem:**
```sql
-- Pattern matching anywhere in text
SELECT * FROM posts WHERE content LIKE '%database%';

Problem:
â”œâ”€> B-tree can't help (not a prefix match)
â”œâ”€> Must scan every character of every post
â”œâ”€> O(n Ã— m) where n=rows, m=content length
â””â”€> Exponentially slower as content grows! ğŸ˜±
```

**Solution: Inverted Index**
```markdown
Traditional (Document â†’ Words):
doc1: "B-trees are fast and reliable"
doc2: "Hash tables are fast but limited"

Inverted (Word â†’ Documents):
b-trees  â†’ [doc1]
fast     â†’ [doc1, doc2]
reliable â†’ [doc1]
hash     â†’ [doc2]
tables   â†’ [doc2]
limited  â†’ [doc2]

Query "fast" â†’ [doc1, doc2] in O(1)!
```

**How It Works:**
```markdown
Indexing Pipeline:

1. Tokenization
   "B-trees are FAST!" â†’ ["B", "trees", "are", "FAST"]

2. Normalization
   ["B", "trees", "are", "FAST"] â†’ ["b", "trees", "fast"]

3. Stop Words Removal
   ["b", "trees", "fast"] â†’ ["trees", "fast"]
   (remove common words: "the", "are", "is")

4. Stemming
   ["trees", "fast"] â†’ ["tree", "fast"]
   (reduce to root form)

5. Build Index
   tree â†’ [doc1, doc3, doc5]
   fast â†’ [doc1, doc2, doc7]

Advanced Features:
â”œâ”€ Term frequency (how often word appears)
â”œâ”€ Relevance scoring (best matches first)
â”œâ”€ Fuzzy matching ("databas" matches "database")
â””â”€ Phrase queries ("machine learning" as exact phrase)
```

**Real-World Examples:**
```markdown
Elasticsearch:
POST /posts/_doc/1
{
  "title": "Database Indexing",
  "content": "B-trees are the default index type"
}

# Automatic inverted index creation
# Query:
GET /posts/_search
{
  "query": {
    "match": {
      "content": "database index"  # Matches "Database Indexing"!
    }
  }
}

Other Examples:
â”œâ”€ GitHub code search
â”œâ”€ Slack message search
â”œâ”€ Google Docs search
â””â”€> Any text search uses inverted indexes!
```

**Trade-offs:**
```markdown
âœ… Benefits:
â”œâ”€ Fast text search (milliseconds)
â”œâ”€ Natural language queries
â”œâ”€ Relevance ranking
â””â”€> Fuzzy/synonym matching

âŒ Costs:
â”œâ”€ Large storage overhead (100-200% of original)
â”œâ”€ Expensive updates (re-index many terms)
â”œâ”€ Complex analysis pipeline
â””â”€> Need specialized systems (Elasticsearch, Lucene)

Best for: Full-text search, logs, documents
```

---

## Optimization Patterns

### 1. Composite Indexes

**Problem:**
```sql
-- Typical social media query
SELECT * FROM posts
WHERE user_id = 123
  AND created_at > '2024-01-01'
ORDER BY created_at DESC;

-- Naive approach (two indexes):
CREATE INDEX idx_user ON posts(user_id);
CREATE INDEX idx_time ON posts(created_at);

Execution:
â”œâ”€ Use idx_user â†’ Find all posts by user 123 (maybe 1000 rows)
â”œâ”€ Use idx_time â†’ Find all posts after date (maybe 100K rows)
â”œâ”€ Intersect results (expensive!)
â””â”€> Sort final results by created_at (expensive!)
```

**Solution: Composite Index**
```sql
-- One index, multiple columns
CREATE INDEX idx_user_time ON posts(user_id, created_at);

B-tree Structure:
(1, 2024-01-01)  â—„â”€â”€ User 1's posts, sorted by time
(1, 2024-01-02)
(1, 2024-01-03)
(2, 2024-01-01)  â—„â”€â”€ User 2's posts, sorted by time
(2, 2024-01-02)
(3, 2024-01-01)

Execution:
â”œâ”€ Find first entry for user_id=123
â”œâ”€ Scan sequentially until created_at > date
â””â”€> Already sorted! No extra work needed! âœ…
```

**Column Order Matters:**
```markdown
Index: (user_id, created_at)

âœ… Can efficiently answer:
â”œâ”€ WHERE user_id = 123
â”œâ”€ WHERE user_id = 123 AND created_at > date
â””â”€> WHERE user_id = 123 ORDER BY created_at

âŒ Cannot efficiently answer:
â”œâ”€ WHERE created_at > date (wrong prefix)
â””â”€> ORDER BY created_at (needs user_id first)

Rule: Order columns from most selective to least
      OR based on query patterns (filter â†’ sort)
```

**Common Patterns:**
```sql
-- E-commerce orders
CREATE INDEX idx_customer_date ON orders(customer_id, order_date);
-- Query: "Show my recent orders"

-- Event processing
CREATE INDEX idx_status_priority ON events(status, priority, created_at);
-- Query: "Process pending high-priority events"

-- Activity feeds
CREATE INDEX idx_user_type_time ON activities(user_id, type, timestamp);
-- Query: "Show user's likes, sorted by time"
```

---

### 2. Covering Indexes

**Problem:**
```sql
-- Social feed query
SELECT user_id, created_at, likes
FROM posts
WHERE user_id = 123
ORDER BY created_at DESC;

-- With regular index
CREATE INDEX idx_user_time ON posts(user_id, created_at);

Execution:
â”œâ”€ Traverse index to find matching posts
â”œâ”€ For each post_id found in index:
â”‚   â””â”€> Read full row from table to get 'likes' column ğŸ˜±
â”œâ”€ If 20 posts â†’ 20 additional disk reads!
â””â”€> Slow for large result sets
```

**Solution: Include Extra Columns**
```sql
-- Covering index (PostgreSQL)
CREATE INDEX idx_user_time_likes
ON posts(user_id, created_at) INCLUDE (likes);

Execution:
â”œâ”€ Traverse index
â”œâ”€ Index contains ALL needed columns!
â””â”€> Return results directly from index âœ…
    No table lookups needed!
```

**When to Use:**
```markdown
âœ… Good scenarios:
â”œâ”€ Query frequently-run, only needs few columns
â”œâ”€ Read-heavy workload
â”œâ”€ Column values small (integers, not TEXT)
â””â”€> Performance critical (leaderboards, feeds)

âŒ Avoid when:
â”œâ”€ Table has frequent writes (index maintenance cost)
â”œâ”€ Included columns are large (bloats index)
â”œâ”€ Many different query patterns (can't cover all)
â””â”€> Query optimizer already efficient

Reality in 2025:
â””â”€> Modern optimizers are smart
    Covering indexes are niche optimization
    Focus on simpler strategies first!
```

**Example:**
```sql
-- Leaderboard query (frequently run)
SELECT username, score
FROM users
WHERE game_id = 1
ORDER BY score DESC
LIMIT 10;

-- Covering index
CREATE INDEX idx_game_score
ON users(game_id, score DESC) INCLUDE (username);
-- Returns top 10 purely from index!
```

---

### 3. Partial Indexes

**Concept:**
```sql
-- Index only subset of rows
CREATE INDEX idx_active_users
ON users(username)
WHERE active = true;

Benefits:
â”œâ”€ Smaller index size
â”œâ”€ Faster to update
â””â”€> Still fast for filtered queries!
```

**When to Use:**
```markdown
Scenarios:
â”œâ”€ Most queries filter on same condition
â”‚   Example: "WHERE status = 'active'"
â”‚
â”œâ”€ Small subset of data accessed frequently
â”‚   Example: 90% of orders are 'completed'
â”‚              Only 10% are 'pending' (what we query)
â”‚
â””â”€> Save space and maintenance cost!
```

---

## Interview Templates

### Template 1: When to Add Index

```markdown
Interviewer: "How do you decide which columns to index?"

You:
"I look at the query patterns first. Indexes are most valuable for:

1. WHERE clause columns
   â””â”€> Filtering large result sets

2. JOIN columns
   â””â”€> Both sides of the join

3. ORDER BY columns
   â””â”€> Avoid expensive sorting

4. Frequently queried columns
   â””â”€> Based on access patterns from APIs

For example, in a Twitter-like system:
â”œâ”€ tweets(user_id) - for 'show user's tweets'
â”œâ”€ tweets(user_id, created_at) - composite for timeline
â””â”€> likes(tweet_id) - for counting likes

I avoid indexing:
â”œâ”€ Small tables (< 1000 rows)
â”œâ”€ Low cardinality columns (gender, boolean)
â”œâ”€ Columns rarely queried
â””â”€> Write-heavy tables with infrequent reads

The goal is balance: fast queries without write penalties."

Time: 1-2 minutes
```

### Template 2: Index Type Selection

```markdown
Interviewer: "What type of index would you use?"

You:
"Default to B-trees - they handle both exact matches and range queries.

But there are specialized cases:

1. Geospatial queries (nearby restaurants)
   â””â”€> Use geospatial index (geohash or R-tree)
   â””â”€> Because lat/long need 2D proximity search

2. Full-text search (search blog posts)
   â””â”€> Use inverted index (Elasticsearch)
   â””â”€> Because pattern matching anywhere in text

3. Write-heavy workloads (logging, metrics)
   â””â”€> Consider LSM-tree database (Cassandra)
   â””â”€> Because batched writes are 10-100x faster

4. Exact-match only, in-memory
   â””â”€> Maybe hash index (Redis)
   â””â”€> But B-trees usually fine too

For 90% of cases, B-tree is the right answer."

Time: 1-2 minutes
```

### Template 3: Composite Index Design

```markdown
Interviewer: "How would you index this query?"

Query:
SELECT * FROM orders
WHERE customer_id = 123
  AND status = 'shipped'
ORDER BY order_date DESC;

You:
"I'd create a composite index on (customer_id, status, order_date):

CREATE INDEX idx_orders
ON orders(customer_id, status, order_date DESC);

Column order matters:
1. customer_id first - most selective, always in WHERE
2. status second - also in WHERE clause
3. order_date last - used for ORDER BY

This single index handles:
â”œâ”€ Filtering by customer
â”œâ”€ Filtering by status
â””â”€> Sorting by date (no extra sort needed!)

The database can:
â”œâ”€ Seek to customer 123
â”œâ”€ Scan entries matching status
â””â”€> Results already in date order âœ…

Alternative approach: If we mostly query just by customer_id,
I might do (customer_id, order_date) to keep index smaller."

Time: 1-2 minutes
```

### Template 4: Geospatial Indexing

```markdown
Interviewer: "How would you find nearby restaurants?"

You:
"Regular B-trees don't work well for this because they treat
latitude and longitude as independent dimensions. We need an
index that understands 2D spatial relationships.

Two main approaches:

1. Geohash (simpler):
   â”œâ”€ Convert lat/lng to 1D string: 'dr5ru7'
   â”œâ”€ Nearby locations share prefix
   â”œâ”€ Use regular B-tree on geohash strings
   â””â”€> Works in any database (Redis, MongoDB)

2. R-tree (more powerful):
   â”œâ”€ Hierarchical bounding boxes
   â”œâ”€ Flexible, overlapping rectangles
   â”œâ”€ Handles shapes (not just points)
   â””â”€> Standard in PostGIS, MySQL spatial

For most applications, geohash is sufficient:
CREATE INDEX idx_geohash ON restaurants(geohash);

Query nearby:
SELECT * FROM restaurants
WHERE geohash BETWEEN 'dr5ru' AND 'dr5ru~';

Then filter exact distances in application code."

Time: 2 minutes
```

---

## Quick Reference

### Decision Flowchart

```markdown
Need to optimize query?
    â”‚
    â”œâ”€> Exact match only? (id = 123)
    â”‚   â””â”€> B-tree âœ… (default)
    â”‚
    â”œâ”€> Range queries? (age > 25)
    â”‚   â””â”€> B-tree âœ…
    â”‚
    â”œâ”€> Sorting? (ORDER BY created_at)
    â”‚   â””â”€> B-tree âœ… or Composite
    â”‚
    â”œâ”€> Location search? (nearby restaurants)
    â”‚   â””â”€> Geospatial (geohash or R-tree)
    â”‚
    â”œâ”€> Full-text search? (content LIKE '%word%')
    â”‚   â””â”€> Inverted index (Elasticsearch)
    â”‚
    â”œâ”€> Write-heavy? (millions of inserts/sec)
    â”‚   â””â”€> LSM-tree (Cassandra, RocksDB)
    â”‚
    â””â”€> Multiple columns in WHERE/ORDER BY?
        â””â”€> Composite index

When in doubt: B-tree! ğŸ¯
```

### Performance Numbers

```markdown
Operation                    | Time (Approximate)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
B-tree lookup               | 1-10ms (2-3 disk reads)
Full table scan (1M rows)   | 1-5 seconds
Hash index lookup           | 1-5ms (O(1))
Geohash proximity search    | 10-50ms
R-tree spatial query        | 20-100ms
Inverted index text search  | 10-100ms
LSM tree write              | 0.1-1ms (buffered)
B-tree write                | 5-20ms (immediate)

Rule of thumb:
â”œâ”€ Index improves reads: 100-1000x
â”œâ”€ Index slows writes: 2-5x
â””â”€> Worth it for read-heavy workloads!
```

### Common Mistakes

```markdown
âŒ DON'T:
â”œâ”€ Index every column "just in case"
â”œâ”€ Create hash indexes by default
â”œâ”€ Ignore write performance impact
â”œâ”€ Use LIKE '%pattern%' and expect index help
â”œâ”€ Index small tables (< 1000 rows)
â””â”€> Forget to maintain indexes (VACUUM, ANALYZE)

âœ… DO:
â”œâ”€ Start with B-trees
â”œâ”€ Profile queries first (EXPLAIN)
â”œâ”€ Index based on access patterns
â”œâ”€ Use composite indexes for multi-column queries
â”œâ”€ Monitor slow query logs
â””â”€> Remove unused indexes periodically
```

### Pre-Interview Checklist

```markdown
Core Concepts:
â–¡ Understand why indexes exist (minimize disk reads)
â–¡ Know trade-offs (fast reads, slow writes, storage)
â–¡ Can explain B-tree structure and traversal

Index Types:
â–¡ B-tree: Default choice, versatile
â–¡ LSM: Write-heavy workloads
â–¡ Hash: Rarely used (know why!)
â–¡ Geospatial: Location queries
â–¡ Inverted: Full-text search

Optimization:
â–¡ Composite indexes (column order matters)
â–¡ Covering indexes (niche optimization)
â–¡ When to avoid indexes

Interview Strategy:
â–¡ Always ask about access patterns first
â–¡ Default to B-trees unless special case
â–¡ Explain trade-offs clearly
â–¡ Know 1-2 real-world examples per type
```

---

## Practice Scenarios

### Scenario 1: Twitter Timeline

**Requirements:**
- Show user's feed (tweets from followed users)
- Sort by most recent
- 1 million tweets per user

**Schema:**
```sql
CREATE TABLE tweets (
    id BIGINT PRIMARY KEY,
    user_id BIGINT,
    content TEXT,
    created_at TIMESTAMP
);

CREATE TABLE follows (
    follower_id BIGINT,
    followee_id BIGINT,
    PRIMARY KEY (follower_id, followee_id)
);
```

**Indexes Needed:**
```sql
-- For feed query
CREATE INDEX idx_tweets_user_time
ON tweets(user_id, created_at DESC);

-- For follow lookup
CREATE INDEX idx_follows_followee
ON follows(followee_id);

-- For user's own tweets
CREATE INDEX idx_tweets_user
ON tweets(user_id);

Query:
SELECT t.*
FROM tweets t
JOIN follows f ON t.user_id = f.followee_id
WHERE f.follower_id = 123
ORDER BY t.created_at DESC
LIMIT 20;
```

---

### Scenario 2: Uber Driver Matching

**Requirements:**
- Find nearby drivers (within 5km)
- Consider driver status (available/busy)
- Real-time updates (millions/sec)

**Schema:**
```sql
CREATE TABLE drivers (
    id BIGINT PRIMARY KEY,
    name VARCHAR(255),
    status VARCHAR(20),
    latitude DECIMAL(10, 8),
    longitude DECIMAL(11, 8),
    geohash VARCHAR(12),
    updated_at TIMESTAMP
);
```

**Indexes Needed:**
```sql
-- Geospatial for proximity
CREATE INDEX idx_geohash_status
ON drivers(geohash, status);

-- Or use PostGIS
CREATE INDEX idx_location
ON drivers USING GIST(ST_MakePoint(longitude, latitude));

Query:
SELECT *
FROM drivers
WHERE geohash BETWEEN 'dr5ru' AND 'dr5ru~'
  AND status = 'available'
  AND updated_at > NOW() - INTERVAL '1 minute'
ORDER BY ST_Distance(location, rider_location)
LIMIT 10;
```

---

### Scenario 3: E-commerce Product Search

**Requirements:**
- Full-text search in product names/descriptions
- Filter by category, price range
- Sort by relevance or price

**Schema:**
```sql
CREATE TABLE products (
    id BIGINT PRIMARY KEY,
    name VARCHAR(255),
    description TEXT,
    category_id INT,
    price DECIMAL(10, 2),
    created_at TIMESTAMP
);
```

**Indexes Needed:**
```sql
-- Full-text search (PostgreSQL)
CREATE INDEX idx_search
ON products USING GIN(to_tsvector('english', name || ' ' || description));

-- Category + price (composite)
CREATE INDEX idx_category_price
ON products(category_id, price);

-- Or use Elasticsearch
POST /products/_doc/1
{
  "name": "iPhone 15",
  "description": "Latest smartphone",
  "category": "Electronics",
  "price": 999
}

Query (Elasticsearch):
GET /products/_search
{
  "query": {
    "bool": {
      "must": { "match": { "name": "phone" } },
      "filter": [
        { "term": { "category": "Electronics" } },
        { "range": { "price": { "lte": 1000 } } }
      ]
    }
  },
  "sort": [ { "_score": "desc" } ]
}
```

---

## Final Tips

```markdown
Interview Strategy:

1. Clarify Requirements First
   â”œâ”€ Read or write heavy?
   â”œâ”€ Query patterns?
   â””â”€> Scale (rows, queries/sec)?

2. Start Simple
   â”œâ”€ B-tree for most cases
   â””â”€> Explain why it works

3. Identify Special Cases
   â”œâ”€ Location? â†’ Geospatial
   â”œâ”€ Text search? â†’ Inverted
   â”œâ”€ Write-heavy? â†’ LSM
   â””â”€> Explain trade-offs

4. Consider Optimization
   â”œâ”€ Composite for multi-column
   â”œâ”€ Covering if frequently-run
   â””â”€> But don't over-engineer!

5. Discuss Monitoring
   â”œâ”€ Slow query logs
   â”œâ”€ Index usage stats
   â””â”€> Remove unused indexes

Remember:
"There's no perfect answer. Show your reasoning!"

Key soundbites:
â”œâ”€ "B-trees are the default because they're versatile"
â”œâ”€ "Indexes trade storage and write speed for read speed"
â”œâ”€ "Column order matters in composite indexes"
â””â”€> "Always profile before optimizing"
```

---

Good luck with your interviews! ğŸš€

**Most Important Takeaways:**
1. **B-trees are default** - versatile, handle 90% of cases
2. **Know the trade-offs** - fast reads vs slow writes
3. **Access patterns drive decisions** - analyze queries first
4. **Composite indexes** - powerful for multi-column queries
5. **Special cases** - geospatial (location), inverted (text), LSM (writes)